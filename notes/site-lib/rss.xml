<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[obsidian]]></title><description><![CDATA[Obsidian digital garden]]></description><link>http://github.com/dylang/node-rss</link><image><url>site-lib/media/favicon.png</url><title>obsidian</title><link/></image><generator>Webpage HTML Export plugin for Obsidian</generator><lastBuildDate>Thu, 11 Sep 2025 00:31:22 GMT</lastBuildDate><atom:link href="site-lib/rss.xml" rel="self" type="application/rss+xml"/><pubDate>Thu, 11 Sep 2025 00:31:18 GMT</pubDate><ttl>60</ttl><dc:creator/><item><title><![CDATA[Shankar QM - Chapter 1]]></title><description><![CDATA[n-dimensional Real Vector Space: n-dimensional Complex Vector Space: Vectors in a given vector space are represented using Dirac braket notation:
Where are vector that form a basis for , and are scalars.Inner product is a map between two vectors and onto the scalars, denoted by:
Where is the field of the vector space (either or ), which satisfies the following axioms: = For complex vector spaces, commuting and inverts the complex part of the inner product The inner product of a vector with itself (magnitude) is non-negative The only vector with magnitude zero is the zero vector. Linearity on the ket term. Bra distributes on ket. Inner product space is a vector space with an inner productIf one tries to distribute the ket term on the bra term:
The scalars are conjugated (anti-symmetry on the first term)Orthogonal vectors: Norm of a vector: Orthonormal Basis: All basis vectors have norm 1 and orthogonal between them.Given and the inner product must obey:If the basis chosen was orthonormal, then and so:The dual space of a vector space is denoted is the set of all linear functions from to the scalars.If the elements of are column vectors, then elements of should map column vectors to scalars, therefore the elements of are row vectors.There exists a canonical map between and such that if a vector is mapped to a co-vector denoted , the application of to a vector equals the inner product of and , denoted .In the context of QM, vectors are called ket and co-vectors are called bra.Given and , then for the above to be true:Here, the vector is expanded in an orthonormal basis , where the components are , i.e. the inner product of each basis vector with .If the ket corresponds to , then because of the conjugation applied corresponds to .In braket notation it is allowed to place scalars inside the braket, signifying for kets:
and for bras:
More generally, an equation among kets:
This implies an adjoint equation:
The expansion
can also be "adjointed" into:
Notice how the inner product is commuted to , because in the sum that term corresponds to scalars, it has to be conjugated, which is equivalent to commuting the order of the terms.This process converts any basis to an orthonormal one.
Non-orthonormal basis: , , etc.
Transforms to orthonormal basis: , , etc.
Rescale the first vector by its own length so it becomes a unit vector. This will be the first unit vector. Subtract from the second vector its projection along the first orthonormal vector and rescale to obtain a unit vector Subtract from the third vector its projection along the first orthonormal vector and its projection along the second orthonormal vector. and rescale to obtain a unit vector. Repeat, subtracting all the projections of each vector to the ones before that
Schwarz Inequality: Triangle Inequality: Subspace: A subset of a vector space that also forms a vector space. A subspace "" of dimensionality will be denoted Sum of subspaces: Given two subspaces, their sum can be defined as the vector space containing all elements of both vector spaces and all linear combinations.An operator is a linear function .The action of on can be represented as:
Operators can also act on bras:
Linear operators obey the following rues: And similarly, for bras: Identity operator ( ): and Rotation operator ( ): Rotates vector by about the axis parallel to the unit vector .The action of an operator on a basis: can be used to determine the effect on any vector:In general, The commutator of and is defined as: Identities: The inverse of denoted satisfies Distributing the inverse over a series of operations reverses the order: When acts on the basis we obtain the new basis as done in <a data-href="#Effects on basis" href="shankar-qm-chapter-1.html#Effects_on_basis_0" class="internal-link" target="_self" rel="noopener nofollow">Effects on basis</a>, which we know the j-th component for each new basis vector in the original basis is: which is equal to: are the matrix elements of in that basis.If acts on to give then the components of may be calculated:
Which corresponds to the following matrix operation:The columns correspond to the components of the transformed basis vectors.Similarly, if acts on to give the components may be calculated as:The projection operator for the ket is defined as:
It operates on a ket , and "projects" it onto the ket .If one projects onto each basis vector, and then adds up all projections, then you end up with again.Similarly, with bras:
Using the definition of the elements of a matrix representation of an operator, we obtain:
This corresponds to the matrix with zero in all elements except the i-th element in its diagonal.The matrix representation of a product of operations is the product of the matrices of each factor:
Similarly to how a scalar operating on a vector is conjugated when the adjoint is calculated:
A vector being operated by omega can be adjointed by taking the hermitian conjugate or adjoint of the operator denoted .
Given a basis, the components of the adjoint may be calculated as:The matrix representing is the transpose conjugate of the matrix representing .Distribution of adjoint on operators reverses order: When a product involving operators, bras, kets and scalars, one must reverse the order of all factors and make the substitutions , and .
$An operator is hermitian if An operator is anti-hermitian if The same way numbers can be decomposed into real and imaginary parts by
operators can be decomposed into hermitian and anti-hermitian parts:An operator is unitary if this automatically implies The product of two unitary operators is also unitary. Additionally, they are associative and always have an inverse. Therefore, they form a group, named unitary group U(n). They are the generalization of rotation in to They preserve the inner product: The columns of an unitary matrix are column vectors which are orthonormal to each other.An active transformation is a linear map that maps vectors from the vector space to itself.
A passive transformation instead, is applied to operators and is applied to coordinates instead.
Eigenvalue equation:
Where is the eigenket of and its eigenvalue.Because of the linearity of the operator, if is an eigenket, then so is .
We will not treat them as different vectors for the eigenvalue problem.For the identity operator :
All vectors are eigenkets
All eigenkets with eigenvalue 1
For the projection operator on a vector :
Kets parallel to are eigenkets with eigenvalue 1
Kets perpendicular to are eigenkets with eigenvalue 0
For the operator :
Vectors parallel to with eigenvalue 1
Vectors parallel to with eigenvalue . Vectors parallel to with eigenvalue .
From we obtain:
Assuming the inverse of ) exists:
But there is no linear operator that transforms the vector to . Therefore the inverse doesn't exist, and so:
Using the Leibniz formula for determinants we can conclude that this is a polynomial equation of variable with coefficients determined by : is the characteristic polynomial and the above equation is the characteristic equation. Its roots are the eigenvalues, independent of the basis.Eigenvectors may be labeled by their eigenvalue. For example for :This notation assumes that the eigenvalues are different for every vector, which only occurs if the polynomial doesn't have repeated roots (i.e. non-degenerate)The eigenvalues of a Hermitian operator are real:
If is hermitian then is real. For every hermitian operator there exists a basis consisting of its eigenvectors which are orthonormal. The matrix representation of the operator consists of its eigenvalues in its diagonalIf the characteristic equation of is non-degenerate then there is only one orthonormal basis formed by its eigenvectors. If it's degenerate, then there are many such basis. Eigenvectors may span an eigenspace with value .If a root is repeated times for some eigenvalue , then there will be an eigenspace .For degenerate eigenvalue problems, a ket in a degenerate eigenspace is denoted where labels the specific ket.The eigenvalues of a unitary operator are complex values with unit modulusThe eigenvectors of a unitary operator are mutually orthogonal. (Assuming no degeneracy)If starting from an orthonormal basis, one changes to the basis generated by the eigenvectors of a hermitian operator , because the eigenvectors are also orthonormal, the change of basis corresponds to a rotation of one orthonormal basis to another. This action is performed by unitary operator:We can conclude then, that hermitian matrices (columns contains orthonormal basis), may be "rotated backwards" to the original orthonormal basis , therefore diagonalizing the matrix. In other words:
Every hermitian matrix may be diagonalized by a unitary change of basis.Or in terms of a passive transformation:If is a hermitian matrix, there exists a unitary matrix (Built out of the eigenvectors of ) such that is diagonal.This is equivalent to the eigenvalue problem. The general case of matrix diagonalization is but if is hermitian, then is unitary, and .Theorem: If and are two commuting () Hermitian operators, there exists (at least) a basis of common eigenvectors that diagonalizes them both.If at least one of the operators are non-degenerate: Every eigenvector of is an eigenvector of and vice-versa.<br><img alt="Pasted image 20250112233241.png" src="learning/shankar-qm/attachments/pasted-image-20250112233241.png" target="_self" style="width: 500px; max-width: 100%;">Initial conditions (, , , )This problem can be expressed as the following matrix equation:One must think of the state of the system as vector that's a function in time: this is an abstract vector that represents the position of the system. The most intuitive basis is the one where the unit vectors correspond to unit displacement of moth masses. This basis is denoted by and :
One may also double-differentiate the equation to obtain its second derivative:
The vectors and are related by an operator , in this basis the operator can be found to be represented by the matrix:From now on will refer to the operator AND the matrix in this original basis.From Newtonian mechanics, one can derive:And in general, the following is true:The difficulty in solving this is the coupling between two differential equations.The trick is to change basis to one where is diagonal. This new basis will have basis vectors and . The change of basis matrix will be named .Because is hermitian, will be unitary, and so we can write:
We will label the values of the diagonal of as:
We can easily find what happens if we feed the basis vectors and (in this new basis):
We can then write the vector form of the above equation, as its true for all basis:
From this we conclude that are the eigenvalues of and are the eigenvectors. And because of the definition of , the i-th column of U corresponds to the components of in the , basis.In this basis, the equation becomes:Which is much simpler to solve.Finding the eigenvalues of can be done by the determinant method:Solving this equation, we obtain:
And finding the eigenvectors in the original basis , we can express :The inital conditions () in the original basis are given by To find the initial condition in the new basis, we multiply the components by to obtain:
The above matrix equation reduces to:
The above are second order homogeneous differential equations, with the following solutions for the given initial conditions:
Now we know the vector for the new basis, we can transform to the old basis by multiplying by Substituting, we obtain:Which is the result we wantedThe result of the above problem can be rewritten as a matrix equation:The middle matrix is called the propagator. By multiplying the initial state vector with the propagator, we obtain the final state vector. The propagator is independent of the initial state.This relation can be expressed in vectors as:
Note: is not the change of basis matrix from before. It's the propagatorThe propagator only depends on the eigenvalues and eigenvectors, therefore, the problem can be solved in this manner:
Solve the eigenvalue problem for Construct propagator Solution is This equation has a simpler form in the basis :In this basis, if the system has initial state , by applying the propagator, we see that the state evolves with only a factor of .
These are called the normal modes, and correspond to the columns of the propagator.For this example if the system starts in either or the oscillating modes correspond respectively to:
Both masses oscillating in tandem
Both masses oscillating in opposite direction to one another.
If the system starts in a linear combination of this two modes, it evolves into the linear combination of the normal modes.c-number: (classical) refers to scalars that commute
q-number: (quantum) refers to operators that don't generally commuteFunctions of q-numbers as a power series:Calculating this power series to determine it's value, or even if it converges is done in the basis in which is diagonal.Definition:
If it's written in some basis, one can just differentiate the element of the matrix.Only if (all its eigenvalues are less than 1)And it's also a unitary operatorAssuming exists.Solution:
For q-numbers the following is true:
The chain rule for exponentiating operators is as follows:
We can commute the term with but NOT with Because does not commute with , the following IS NOT TRUE:
As that would imply the terms commute.To generalize to vector spaces of infinite dimension, we need to redefine the inner product:Where and are functions defined from to , which correspond to coordinates of vector elements in the vector space.To define basis vectors for this space, they must obey the following properties. For two given basis vectors and Where is the Dirac delta functionThis is in order to satisfy the general completeness relation :
When the above expression is operated on the left by and on the right by one obtains:If one replaces the basis with Or more generally:
Operating on gives . Or equivalently,Definition: Related to delta function by: Operators acts on functions to give another functionThey can be represented by an infinite dimensional "matrix". Defined as:
Matrix elements: is not hermitian.Contrary to finite dimensional case, is not a sufficient condition for the operator to be hermitian. It depends on the spaceThe condition is:The space of functions that can be normalized to unity or to the dirac delta, is the physical Hilbert spaceIs hermitian under the previous condition
Eigenvectors:By solving we can express the solutions for a basis as:
Where we define Normalizing:
The operator that has as eigenbasis the basis is the X operator.The action on a function in the x basis is: There exists a duality between the K operator and X operator:Passing from X to K basis and from K to X basis is equivalent to taking the Fourier transform and inverse Fourier transform of the components of the vector.X and K do not commute: Consider a string from to . The displacement obeys:Given the initial displacement of and the let the initial velocity be determine the evolution of the string.By representing the state of the string using a vector, we write:
Which is equivalent to:
We may now attempt to find the eigenvectors and eigenvalues of in order to construct the operator and then apply it to The eigenvalue equation is:
Equivalent to:
This can be solved as a differential equation. The solutions that obey the boundary conditions are:This are the eigenvectors of .
We label the eigenvectors as . By applying to we find the eigenvalues to be: Projecting the wave equation into we obtain:
And by solving this differential equation: are components of . Expressing in terms of these components:
And using the found expression of :
Factoring out :
And by the definition of : . The propagator equals:When one wants to find the evolution of the string given one can apply it to the propagator in the X basis:One can then calculate ]]></description><link>shankar-qm-chapter-1.html</link><guid isPermaLink="false">Personal/Some of My Notes/Shankar QM - Chapter 1.md</guid><pubDate>Thu, 11 Sep 2025 00:31:12 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Index]]></title><description><![CDATA[I'm trying out obsidian as a note taking system. If I'm happy on how a particular thing I've written turns out, I will try to publish it here.Also I want to start documenting various topics I'm learningI audited the first half of the Quantum Mechanics course (Sakurai-based), taught by the Dr. Juan Pablo Paz at the University of Buenos Aires in 2025. Topics covered in this half include:
Spin-1/2 system, Stern-Gerlach experiment
Postulates of QM
Pure and mixed states
Schrodinger, Heisenberg and Interaction pictures
Harmonic Oscilator
Composite Systems and entaglement
Introduction to the quanitzation of the EM field
Notes (Spanish): <a data-href="Fisica Teoria 2" href="fisica-teoria-2.html" class="internal-link" target="_self" rel="noopener nofollow">Fisica Teoria 2</a>Summery of linear algebra concepts, came very handy for the Física Teórica 2 course!<br><a data-href="Shankar QM - Chapter 1" href="shankar-qm-chapter-1.html" class="internal-link" target="_self" rel="noopener nofollow">Shankar QM - Chapter 1</a>]]></description><link>index.html</link><guid isPermaLink="false">Personal/Some of My Notes/Index.md</guid><pubDate>Thu, 11 Sep 2025 00:24:40 GMT</pubDate></item><item><title><![CDATA[CC-BY-NC-SA]]></title><description><![CDATA[<img src="attachments/cc-by-nc-sa.png" target="_self">]]></description><link>attachments/cc-by-nc-sa.html</link><guid isPermaLink="false">Personal/Some of My Notes/attachments/CC-BY-NC-SA.png</guid><pubDate>Thu, 11 Sep 2025 00:17:09 GMT</pubDate><enclosure url="attachments/cc-by-nc-sa.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="attachments/cc-by-nc-sa.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Fisica Teoria 2]]></title><description><![CDATA[Un operador hermítico puede descomponerse por sus autovalores y los proyectores a los autoespacios asociados a cada autovalor de la siguiente manera: y hermitico.
Si y es no degenerado, entonces los autovectores de tambien son autovectores de . Pero los autovecores de no necesariamente son autovectores de .
El estado de todo sistema físico está representado por un vector (de norma
unidad) en un espacio de Hilbert ().Dimensión = Cantidad de resultados de una medición exhaustivaTodas las propiedades observables de un sistema físico se representan con
operadores lineales hermíticos que actúan sobre . Denominados Un operador tiene autovalores y proyectores a sus autoespacios asociados En el caso de que NO sea degenerado:
Donde es el autovector asociado a En el caso de que SI sea degenerado:
donde es el -esimo autovector asociado a y forman una base ORTONORMAL del autoespacio. Los resultados posibles de la medición de cualquier observable son sus autovalores Si el estado de un sistema es , la probabilidad de obtener el resultado en la medición del observable es siempre: En caso de que NO sea degenerado: En caso de que SI sea degenerado: Si el estado de un sistema es y medimos el observable y detectamos el autovalor , entonces el estado del sistema después de la medición se obtiene a partir de la proyección de sobre el subespacio asociado al autovalor El denominador es necesarrio para normalizarEl valor esperado (o medio) de se define para un estado implicito :
Que es igual a:
La dispersión de se define como:
Partiendo de la desigualdad de Shwarz que establece:
Y eligiendo los kets y Se puede demostrar:Aplicado a los operadores y Un operador interactua con un estado puro mediante los postulados de probabilidad y colapso. Para el cálculo de la probabilidad: El estado tambien se puede representar como el proyector con la propiedad Si un estado puede estar en diferentes estados posibles cada uno con probabilidad se lo denomina un ensamble se puede hablar de un estado mixto descripto por el operador densidad (o matriz densdiad). La aleatoridad en este caso proviene de IGNORANCIA del sistema.
Este operador generaliza las propiedades de los estados puros. Los estados puros y sus probabilidades se lo puede pensar como la descomposición espectral del estado mixto. Ademas: es hermítico para todo (Semidefinido positivo)
Valor que cuantifica cuan puro o mixto es un estado
Caso estado puro: Caso estado máxima ignorancia: Bases ortonormales (Las bases canonicas son definidas para spin up y down en z):Spines en otras direcciones se definen:Cumplen la propiedad que (Spin opuestos son ortogonales)
Cumplen la propiedad que (Spin opuestos son ortogonales)Las mediciones que se pueden realizar consiste de medir el spin en una dirección y pueden ser +1 o -1. Si se respeta la base, los operadores son:
Donde , y son las Matrices de Pauli:La medición de spin en la dirección corresponde al operador El proyector al autoespacio asociado a la medición es Si se mide spin en la dirección dada por los angulos y : <img alt="spin-1-2-n-vector.png" src="archive/fisica-teorica-2/attachments/spin-1-2-n-vector.png" target="_self" style="width: 300px; max-width: 100%;">
El operador asociado es:Con los estados de spin +1 y -1 asociados: Generalizando los estados de spin a matrices densidad:
Donde es el vector polarización.
El modulo de se relaciona con la pureza: Se pueden representar en la esfera de Bloch:<br><img alt="bloch.png" src="archive/fisica-teorica-2/attachments/bloch.png" target="_self" style="width: 350px; max-width: 100%;">Si uno tiene un sistema compuesto por dos subsistemas A y B con espacios de estados y el estado del sistema compuesto es un elemento del espacio Este espacio tiene una base donde son los ket base de y son los ket base de . Los estados de que son producto de dos estados de y se doneminan estados producto : Si NO corresponde a el producto de dos estados, se donomina estado entrelazado.La forma general de escribir un estado compuesto es:Dada la base de operadores sobre y denodadas y , con dimensiones y respectivamente se definen los operadores sobre :
La traza parcial de un operador sobre y se definen:La matriz densidad reducida se define como:_El operador de evolución temporal infinitesimal es generado por el Hamitoniano. transforma estados del tiempo al estado en el tiempo :
Es unitario Composición: Cumple la ecuación:
Donde es el operador Hamiltoniano
Donde Donde es la funcion escalón de HeavisideEl operador de evolución temporal afecta a los estados:
Esto lleva a la ecuacion de Schrodinger
La ecuación de Schrodinger se reduce a un problema de autovalores del Hamiltoniano.Si uno conoce los autovalores y autoestados del Hamiltoniano: Cualquier estado puede ser escrito como combinacion lineal: Por la ortogonalidad de los autoestados:
El operador evolución se puede expresar como:
El operador de evolución temporal afecta a los operadores:
Mientras que el estado no evoluciona. A partir de esto y la ecuación del operador evolución temporal, cumple:
Hamiltoniano de la forma:
Operador Evolución de : Operador Evolución de : Estado del sistema:
Operadores:
Los operadores evolucionan como en la representación de Heisenberg si el hamiltoniano fuese Ecuacion de evolucion del estado:
Se trabaja con la versión adimensional de y conLa conmutación se convierte en: El hamiltoniano del oscilador armónico es:Donde es el operador destrucción y es el operadoe creación.Relaciones inversas: Conmutador: Hamiltoniano del oscilador armonico cuantico:
El estado que satisface es el estado fundamental con función de onda: (Gausiana de ancho centrada en origen)Los autoestados del hamiltoniano (estados estacionarios) cumplen:
Autovalores de H: Autovalores: Autovectores: (estados estacionarios)Los estados que cumplen: (autoestadods del operador destrucción) cumplen: Incerteza minima Autovalor: Energia clásica: Valor medio de energia: Valor medio de operador numero: ]]></description><link>fisica-teoria-2.html</link><guid isPermaLink="false">Personal/Some of My Notes/Fisica Teoria 2.md</guid><pubDate>Wed, 10 Sep 2025 23:56:36 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Some of my Obsidian Notes]]></title><description><![CDATA[I'm trying out obsidian as a note taking system. If I'm proud of a particular thing I've written, I will try to publish it here.I audited the first half of the Quantum Mechanics course (Sakurai-based), taught by the Dr. Juan Pablo Paz at the University of Buenos Aires in 2025. Topics covered in this half include:
Spin-1/2 system, Stern-Gerlach experiment
Postulates of QM
Pure and mixed states
Schrodinger, Heisenberg and Interaction pictures
Harmonic Oscilator
Composite Systems and entaglement
Introduction to the quanitzation of the EM field
Notes (Spanish): <a data-href="Fisica Teoria 2" href="fisica-teoria-2.html" class="internal-link" target="_self" rel="noopener nofollow">Fisica Teoria 2</a>Summery of linear algebra concepts, came very handy for the Física Teórica 2 course!<br><a data-href="Shankar QM - Chapter 1" href="shankar-qm-chapter-1.html" class="internal-link" target="_self" rel="noopener nofollow">Shankar QM - Chapter 1</a>]]></description><link>some-of-my-obsidian-notes.html</link><guid isPermaLink="false">Personal/Some of My Notes/Some of my Obsidian Notes.md</guid><pubDate>Thu, 11 Sep 2025 00:11:00 GMT</pubDate></item></channel></rss>